{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning\n",
    "## Run Guergiev et al (2017) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General Structure of Network Module**\n",
    "\n",
    "    * Init: Declare layer shapes, data, define spike history buffer, init weights/layers\n",
    "    * init_weights: Loops over all layers and initializes weights\n",
    "       * Hyperparameters\n",
    "            - use_weight_optimization: Desired avg/sd of somatic potentials\n",
    "            - use_feedback_bias: Not in paper - not only synapses Y but also intercept\n",
    "            - use_sparse_feedback: 80% of weights randomly set to 0\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        * TODOs\n",
    "            - Don't loop over layers but sample ones a large set\n",
    "            - Add dropout percentage and magnitude increase vars\n",
    "            \n",
    "    * make_weights_symmetric: \n",
    "        - Hyperparameters: Feedback weights = Transposes feedforward weights\n",
    "            - noisy_symmetric_weights: Add N(0, 0.05) noise to data\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        - TODOs\n",
    "            - use_broadcast only needed with more than one hidden layer!\n",
    "    * init_layers: Loops over layers and adds them to l object in class\n",
    "    * out_f: Forward phase pass through net - calls out_f of different layers in loop\n",
    "    * out_t: Target phase pass through net - adds target at top layer\n",
    "        - TODOs\n",
    "            - merge out_f and out_t - None vs self.t\n",
    "    * f_phase: Forward phase\n",
    "    * t_phase: Target phase\n",
    "    * train: Loop over epochs and loop over all examples\n",
    "    * test_weights\n",
    "    * save_weights\n",
    "    \n",
    "* **Layer Module**\n",
    "\n",
    "    * Init\n",
    "    * spike\n",
    "    \n",
    "* **hiddenLayer**\n",
    "    \n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars\n",
    "    * update_W\n",
    "    * update_Y\n",
    "    * update_A\n",
    "    * update_B\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * plateau_f\n",
    "    * plateau_t\n",
    "    * calc_averages\n",
    "    \n",
    "* **finalLayer**\n",
    "\n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars \n",
    "    * update_W  \n",
    "    * update_B\n",
    "    * update_I\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * calc_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from utils.helpers import *\n",
    "from utils.plotting import *\n",
    "\n",
    "# Guergiev et al (2017) - Segregated Compartments DNN Learning\n",
    "import models.CompDNN as cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download of MNIST needed.\n",
      "No download of Fashion-MNIST needed.\n",
      "No download of CIFAR-10 needed.\n"
     ]
    }
   ],
   "source": [
    "# Create all necessary directory if non-existent\n",
    "global data_dir\n",
    "data_dir = os.getcwd() +\"/data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(\"Created New Data Directory\")\n",
    "    \n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "X_mnist, y_mnist = get_data(num_samples=70000, dataset=\"mnist\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=1./7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\"dnn\", dnn_model, 10,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 5000,\n",
    "                    model_fname =\"temp_model_dnn_mnist\",\n",
    "                    verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence 80% of feedback weights\n",
    "cdl.use_sparse_feedback = False\n",
    "\n",
    "# set training parameters\n",
    "f_etas = (0.21, 0.21)\n",
    "b_etas = None\n",
    "n_epochs = 10\n",
    "n_training_examples = X_train.shape[1]\n",
    "\n",
    "n=(500, 10)\n",
    "# create the network -- this will also load the MNIST dataset files\n",
    "net = cdl.Network(n, X_train, y_train)\n",
    "\n",
    "# train the network\n",
    "net.train(f_etas, b_etas, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (BioDL)",
   "language": "python",
   "name": "biodl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
