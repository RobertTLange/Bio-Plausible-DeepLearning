{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning\n",
    "## Run Guergiev et al (2017) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General Structure of Network Module**\n",
    "\n",
    "    * Init: Declare layer shapes, data, define spike history buffer, init weights/layers\n",
    "    * init_weights: Loops over all layers and initializes weights\n",
    "       * Hyperparameters\n",
    "            - use_weight_optimization: Desired avg/sd of somatic potentials\n",
    "            - use_feedback_bias: Not in paper - not only synapses Y but also intercept\n",
    "            - use_sparse_feedback: 80% of weights randomly set to 0\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        * TODOs\n",
    "            - Don't loop over layers but sample ones a large set\n",
    "            - Add dropout percentage and magnitude increase vars\n",
    "            \n",
    "    * make_weights_symmetric: \n",
    "        - Hyperparameters: Feedback weights = Transposes feedforward weights\n",
    "            - noisy_symmetric_weights: Add N(0, 0.05) noise to data\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        - TODOs\n",
    "            - use_broadcast only needed with more than one hidden layer!\n",
    "    * init_layers: Loops over layers and adds them to l object in class\n",
    "    * out_f: Forward phase pass through net - calls out_f of different layers in loop\n",
    "    * out_t: Target phase pass through net - adds target at top layer\n",
    "        - TODOs\n",
    "            - merge out_f and out_t - None vs self.t\n",
    "    * f_phase: Forward phase\n",
    "    * t_phase: Target phase\n",
    "    * train: Loop over epochs and loop over all examples\n",
    "    * test_weights\n",
    "    * save_weights\n",
    "    \n",
    "* **Layer Module**\n",
    "\n",
    "    * Init\n",
    "    * spike\n",
    "    \n",
    "* **hiddenLayer**\n",
    "    \n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars\n",
    "    * update_W\n",
    "    * update_Y\n",
    "    * update_A\n",
    "    * update_B\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * plateau_f\n",
    "    * plateau_t\n",
    "    * calc_averages\n",
    "    \n",
    "* **finalLayer**\n",
    "\n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars \n",
    "    * update_W  \n",
    "    * update_B\n",
    "    * update_I\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * calc_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from utils.helpers import *\n",
    "from utils.plotting import *\n",
    "\n",
    "# Guergiev et al (2017) - Segregated Compartments DNN Learning\n",
    "import models.CompDNN as cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download of MNIST needed.\n",
      "No download of Fashion-MNIST needed.\n",
      "No download of CIFAR-10 needed.\n"
     ]
    }
   ],
   "source": [
    "# Create all necessary directory if non-existent\n",
    "global data_dir\n",
    "data_dir = os.getcwd() +\"/data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(\"Created New Data Directory\")\n",
    "    \n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "X_mnist, y_mnist = get_data(num_samples=70000, dataset=\"mnist\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=1./7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\"dnn\", dnn_model, 10,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 5000,\n",
    "                    model_fname =\"temp_model_dnn_mnist\",\n",
    "                    verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1.\n",
      "\n",
      "47995\n",
      "Epoch 1, example 1000/47995. QE: 38.00%. T: 2.503s.\n",
      "\n",
      "Epoch 1, example 2000/47995. QE: 29.00%. T: 2.256s.\n",
      "\n",
      "Epoch 1, example 3000/47995. QE: 18.00%. T: 2.284s.\n",
      "\n",
      "Epoch 1, example 4000/47995. QE: 20.00%. T: 2.161s.\n",
      "\n",
      "Epoch 1, example 5000/47995. QE: 18.00%. T: 2.250s.\n",
      "\n",
      "Epoch 1, example 6000/47995. QE: 13.00%. T: 2.181s.\n",
      "\n",
      "Epoch 1, example 7000/47995. QE: 11.00%. T: 2.198s.\n",
      "\n",
      "Epoch 1, example 8000/47995. QE: 19.00%. T: 2.633s.\n",
      "\n",
      "Epoch 1, example 9000/47995. QE: 08.00%. T: 3.072s.\n",
      "\n",
      "Epoch 1, example 10000/47995. QE: 07.00%. T: 2.473s.\n",
      "\n",
      "Epoch 1, example 11000/47995. QE: 14.00%. T: 2.479s.\n",
      "\n",
      "Epoch 1, example 12000/47995. QE: 13.00%. T: 2.487s.\n",
      "\n",
      "Epoch 1, example 13000/47995. QE: 18.00%. T: 2.245s.\n",
      "\n",
      "Epoch 1, example 14000/47995. QE: 12.00%. T: 2.297s.\n",
      "\n",
      "Epoch 1, example 15000/47995. QE: 12.00%. T: 2.212s.\n",
      "\n",
      "Epoch 1, example 16000/47995. QE: 09.00%. T: 2.602s.\n",
      "\n",
      "Epoch 1, example 17000/47995. QE: 17.00%. T: 2.467s.\n",
      "\n",
      "Epoch 1, example 18000/47995. QE: 08.00%. T: 2.748s.\n",
      "\n",
      "Epoch 1, example 19000/47995. QE: 09.00%. T: 2.595s.\n",
      "\n",
      "Epoch 1, example 20000/47995. QE: 14.00%. T: 2.665s.\n",
      "\n",
      "Epoch 1, example 21000/47995. QE: 09.00%. T: 2.456s.\n",
      "\n",
      "Epoch 1, example 22000/47995. QE: 09.00%. T: 2.627s.\n",
      "\n",
      "Epoch 1, example 23000/47995. QE: 12.00%. T: 2.337s.\n",
      "\n",
      "Epoch 1, example 24000/47995. QE: 09.00%. T: 2.586s.\n",
      "\n",
      "Epoch 1, example 25000/47995. QE: 10.00%. T: 2.356s.\n",
      "\n",
      "Epoch 1, example 26000/47995. QE: 07.00%. T: 2.818s.\n",
      "\n",
      "Epoch 1, example 27000/47995. QE: 08.00%. T: 2.365s.\n",
      "\n",
      "Epoch 1, example 28000/47995. QE: 11.00%. T: 2.265s.\n",
      "\n",
      "Epoch 1, example 29000/47995. QE: 12.00%. T: 2.271s.\n",
      "\n",
      "Epoch 1, example 30000/47995. QE: 11.00%. T: 2.244s.\n",
      "\n",
      "Epoch 1, example 31000/47995. QE: 07.00%. T: 2.346s.\n",
      "\n",
      "Epoch 1, example 32000/47995. QE: 06.00%. T: 2.231s.\n",
      "\n",
      "Epoch 1, example 33000/47995. QE: 12.00%. T: 2.217s.\n",
      "\n",
      "Epoch 1, example 34000/47995. QE: 09.00%. T: 2.188s.\n",
      "\n",
      "Epoch 1, example 35000/47995. QE: 06.00%. T: 2.193s.\n",
      "\n",
      "Epoch 1, example 36000/47995. QE: 08.00%. T: 2.255s.\n",
      "\n",
      "Epoch 1, example 37000/47995. QE: 08.00%. T: 2.282s.\n",
      "\n",
      "Epoch 1, example 38000/47995. QE: 07.00%. T: 2.473s.\n",
      "\n",
      "Epoch 1, example 39000/47995. QE: 06.00%. T: 2.324s.\n",
      "\n",
      "Epoch 1, example 40000/47995. QE: 10.00%. T: 2.342s.\n",
      "\n",
      "Epoch 1, example 41000/47995. QE: 08.00%. T: 2.379s.\n",
      "\n",
      "Epoch 1, example 42000/47995. QE: 06.00%. T: 2.608s.\n",
      "\n",
      "Epoch 1, example 43000/47995. QE: 04.00%. T: 2.432s.\n",
      "\n",
      "Epoch 1, example 44000/47995. QE: 05.00%. T: 2.343s.\n",
      "\n",
      "Epoch 1, example 45000/47995. QE: 06.00%. T: 2.227s.\n",
      "\n",
      "Epoch 1, example 46000/47995. QE: 03.00%. T: 2.312s.\n",
      "\n",
      "Epoch 1, example 47000/47995. QE: 05.00%. T: 2.362s.\n",
      "\n",
      "Epoch 1, example 47900/47995.47995\n",
      "Epoch 2, example 1000/47995. QE: 10.00%. T: 5.081s.\n",
      "\n",
      "Epoch 2, example 2000/47995. QE: 08.00%. T: 2.230s.\n",
      "\n",
      "Epoch 2, example 3000/47995. QE: 06.00%. T: 2.335s.\n",
      "\n",
      "Epoch 2, example 4000/47995. QE: 11.00%. T: 2.312s.\n",
      "\n",
      "Epoch 2, example 5000/47995. QE: 04.00%. T: 2.442s.\n",
      "\n",
      "Epoch 2, example 6000/47995."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5ff079913581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m net.train(f_etas, b_etas, n_epochs, save_simulation=False,\n\u001b[1;32m     16\u001b[0m           \u001b[0msimulations_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Simulations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           folder_name=\"Example Simulation\")\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, f_etas, b_etas, n_epochs, save_simulation, simulations_folder, folder_name, overwrite, simulation_notes, current_epoch)\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m                         \u001b[0;31m# we're partway through an epoch; do a quick weight test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                         \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_quick_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\x1b[2K\\rEpoch {0}, example {1}/{2}. QE: {3:05.2f}%. \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mtest_weights\u001b[0;34m(self, n_test)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0;31m# do a forward phase & get the unit with maximum average somatic potential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons_per_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m             \u001b[0msel_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_C_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_neurons_per_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mf_phase\u001b[0;34m(self, x, t, training_num, training)\u001b[0m\n\u001b[1;32m    400\u001b[0m                 \u001b[0mplateau_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;31m# calculate plateau potentials for hidden layer neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplateau_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplateau_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplateau_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mplateau_f\u001b[0;34m(self, plateau_indices)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;31m# calculate apical calcium spike nonlinearity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplateau_indices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_A_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplateau_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplateau_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplateau_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# silence 80% of feedback weights\n",
    "cdl.use_sparse_feedback = False\n",
    "\n",
    "# set training parameters\n",
    "f_etas = (0.21, 0.21)\n",
    "b_etas = None\n",
    "n_epochs = 10\n",
    "n_training_examples = X_train.shape[1]\n",
    "\n",
    "n=(500, 10)\n",
    "# create the network -- this will also load the MNIST dataset files\n",
    "net = cdl.Network(n, X_train, y_train)\n",
    "\n",
    "# train the network\n",
    "net.train(f_etas, b_etas, n_epochs, save_simulation=False,\n",
    "          simulations_folder=\"Simulations\",\n",
    "          folder_name=\"Example Simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (BioDL)",
   "language": "python",
   "name": "biodl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
