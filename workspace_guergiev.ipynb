{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning\n",
    "## Run Guergiev et al (2017) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General Structure of Network Module**\n",
    "\n",
    "    * Init: Declare layer shapes, data, define spike history buffer, init weights/layers\n",
    "    * init_weights: Loops over all layers and initializes weights\n",
    "       * Hyperparameters\n",
    "            - use_weight_optimization: Desired avg/sd of somatic potentials\n",
    "            - use_feedback_bias: Not in paper - not only synapses Y but also intercept\n",
    "            - use_sparse_feedback: 80% of weights randomly set to 0\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        * TODOs\n",
    "            - Don't loop over layers but sample ones a large set\n",
    "            - Add dropout percentage and magnitude increase vars\n",
    "            \n",
    "    * make_weights_symmetric: \n",
    "        - Hyperparameters: Feedback weights = Transposes feedforward weights\n",
    "            - noisy_symmetric_weights: Add N(0, 0.05) noise to data\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        - TODOs\n",
    "            - use_broadcast only needed with more than one hidden layer!\n",
    "    * init_layers: Loops over layers and adds them to l object in class\n",
    "    * out_f: Forward phase pass through net - calls out_f of different layers in loop\n",
    "    * out_t: Target phase pass through net - adds target at top layer\n",
    "        - TODOs\n",
    "            - merge out_f and out_t - None vs self.t\n",
    "    * f_phase: Forward phase\n",
    "    * t_phase: Target phase\n",
    "    * train: Loop over epochs and loop over all examples\n",
    "    * test_weights\n",
    "    * save_weights\n",
    "    \n",
    "* **Layer Module**\n",
    "\n",
    "    * Init\n",
    "    * spike\n",
    "    \n",
    "* **hiddenLayer**\n",
    "    \n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars\n",
    "    * update_W\n",
    "    * update_Y\n",
    "    * update_A\n",
    "    * update_B\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * plateau_f\n",
    "    * plateau_t\n",
    "    * calc_averages\n",
    "    \n",
    "* **finalLayer**\n",
    "\n",
    "    * Init\n",
    "    * create_integration_vars\n",
    "    * clear_vars \n",
    "    * update_W  \n",
    "    * update_B\n",
    "    * update_I\n",
    "    * update_C\n",
    "    * out_f\n",
    "    * out_t\n",
    "    * calc_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from utils.helpers import *\n",
    "from utils.plotting import *\n",
    "\n",
    "# Guergiev et al (2017) - Segregated Compartments DNN Learning\n",
    "import models.CompDNN as cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download of MNIST needed.\n",
      "No download of Fashion-MNIST needed.\n",
      "No download of CIFAR-10 needed.\n"
     ]
    }
   ],
   "source": [
    "# Create all necessary directory if non-existent\n",
    "global data_dir\n",
    "data_dir = os.getcwd() +\"/data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(\"Created New Data Directory\")\n",
    "    \n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "X_mnist, y_mnist = get_data(num_samples=70000, dataset=\"mnist\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=1./7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(\"dnn\", dnn_model, num_epochs,\n",
    "            X_train, y_train, batch_size,\n",
    "            device, optimizer, criterion,\n",
    "            log_freq = 20000,\n",
    "            model_fname =\"temp_model_dnn_mnist\",\n",
    "            verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28)\n",
      "[   28    28 47995]\n",
      "Start of epoch 1.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c3c442f69b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mn_training_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_simulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0msimulations_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Simulations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           folder_name=\"Example Simulation\")\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, f_etas, b_etas, n_epochs, n_training_examples, save_simulation, simulations_folder, folder_name, overwrite, simulation_notes, current_epoch)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;31m# do forward & target phases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrecord_training_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN.py\u001b[0m in \u001b[0;36mf_phase\u001b[0;34m(self, x, t, training_num, training)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_f_phase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# update input spike history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# do a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "# silence 80% of feedback weights\n",
    "cdl.use_sparse_feedback = False\n",
    "\n",
    "# set training parameters\n",
    "f_etas = (0.21, 0.21)\n",
    "b_etas = None\n",
    "n_epochs = 10\n",
    "n_training_examples = X_train.shape[1]\n",
    "\n",
    "n=(500, 10)\n",
    "# create the network -- this will also load the MNIST dataset files\n",
    "net = cdl.Network(n, X_train, y_train)\n",
    "\n",
    "# train the network\n",
    "net.train(f_etas, b_etas, n_epochs,\n",
    "          n_training_examples, save_simulation=False,\n",
    "          simulations_folder=\"Simulations\",\n",
    "          folder_name=\"Example Simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (BioDL)",
   "language": "python",
   "name": "biodl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
