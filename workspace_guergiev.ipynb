{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning\n",
    "## Run Guergiev et al (2017) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext line_profiler\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General Structure of Network Module**\n",
    "\n",
    "    * Init: Declare layer shapes, data, define spike history buffer, init weights/layers\n",
    "    * init_weights: Loops over all layers and initializes weights\n",
    "       * Hyperparameters\n",
    "            - use_weight_optimization: Desired avg/sd of somatic potentials\n",
    "            - use_feedback_bias: Not in paper - not only synapses Y but also intercept\n",
    "            - use_sparse_feedback: 80% of weights randomly set to 0\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        * TODOs\n",
    "            - Don't loop over layers but sample ones a large set\n",
    "            - Add dropout percentage and magnitude increase vars\n",
    "            \n",
    "    * make_weights_symmetric: \n",
    "        - Hyperparameters: Feedback weights = Transposes feedforward weights\n",
    "            - noisy_symmetric_weights: Add N(0, 0.05) noise to data\n",
    "            - use_broadcast: feedback to all layers comes from output layer\n",
    "        - TODOs\n",
    "            - use_broadcast only needed with more than one hidden layer!\n",
    "    * init_layers: Loops over layers and adds them to l object in class\n",
    "    * out_f: Forward phase pass through net - calls out_f of different layers in loop\n",
    "    * out_t: Target phase pass through net - adds target at top layer\n",
    "        - TODOs\n",
    "            - merge out_f and out_t - None vs self.t\n",
    "    * f_phase: Forward phase\n",
    "    * t_phase: Target phase\n",
    "    * train: Loop over epochs and loop over all examples\n",
    "    * test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from utils.helpers import *\n",
    "from utils.plotting import *\n",
    "\n",
    "# Guergiev et al (2017) - Segregated Compartments DNN Learning\n",
    "import models.CompDNN as cdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download of MNIST needed.\n",
      "No download of Fashion-MNIST needed.\n",
      "No download of CIFAR-10 needed.\n"
     ]
    }
   ],
   "source": [
    "# Create all necessary directory if non-existent\n",
    "global data_dir\n",
    "data_dir = os.getcwd() +\"/data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(\"Created New Data Directory\")\n",
    "    \n",
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "X_mnist, y_mnist = get_data(num_samples=70000, dataset=\"mnist\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0,\n",
    "                                                    test_size=1./7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence 80% of feedback weights\n",
    "cdl.use_sparse_feedback = False\n",
    "\n",
    "# set training parameters\n",
    "f_etas = (0.21, 0.21)\n",
    "b_etas = None\n",
    "n_epochs = 10\n",
    "n_training_examples = X_train.shape[1]\n",
    "\n",
    "n=(500, 10)\n",
    "# create the network -- this will also load the MNIST dataset files\n",
    "net = cdl.Network(n, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train| epoch  1| batch 5000/47995| acc: 0.8191| loss: 4.0337| time: 63.20\n",
      "Valid| epoch  1| batch 5000/47995| acc: 0.8198| loss: 4.0337| time: 12.09\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 10000/47995| acc: 0.8914| loss: 2.8728| time: 62.44\n",
      "Valid| epoch  1| batch 10000/47995| acc: 0.8852| loss: 3.0213| time: 10.66\n",
      "-------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtl/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/models/CompDNN_helpers.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  fr_n_param = np.linalg.norm(temp_param)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train| epoch  1| batch 15000/47995| acc: 0.8886| loss: 2.7832| time: 58.59\n",
      "Valid| epoch  1| batch 15000/47995| acc: 0.8874| loss: 2.8413| time: 10.34\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 20000/47995| acc: 0.8946| loss: 2.5731| time: 60.13\n",
      "Valid| epoch  1| batch 20000/47995| acc: 0.8946| loss: 2.5976| time: 9.19\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 25000/47995| acc: 0.9018| loss: 2.5129| time: 54.89\n",
      "Valid| epoch  1| batch 25000/47995| acc: 0.8990| loss: 2.5437| time: 15.76\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 30000/47995| acc: 0.9237| loss: 2.0283| time: 51.60\n",
      "Valid| epoch  1| batch 30000/47995| acc: 0.9184| loss: 2.1685| time: 8.96\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 35000/47995| acc: 0.9322| loss: 1.6569| time: 46.04\n",
      "Valid| epoch  1| batch 35000/47995| acc: 0.9293| loss: 1.7481| time: 9.69\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 40000/47995| acc: 0.9248| loss: 1.9424| time: 47.04\n",
      "Valid| epoch  1| batch 40000/47995| acc: 0.9197| loss: 2.0843| time: 8.88\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  1| batch 45000/47995| acc: 0.9128| loss: 2.2463| time: 52.69\n",
      "Valid| epoch  1| batch 45000/47995| acc: 0.9091| loss: 2.3605| time: 9.71\n",
      "-------------------------------------------------------------------------\n",
      "Train| epoch  2| batch 5000/47995| acc: 0.9445| loss: 1.3440| time: 57.52\n",
      "Valid| epoch  2| batch 5000/47995| acc: 0.9411| loss: 1.4414| time: 10.33\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net.train(f_etas, b_etas, n_epochs,\n",
    "          log_freq=5000, verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import prep_data_guergiev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prep_data_guergiev(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.get_test_error(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (BioDL)",
   "language": "python",
   "name": "biodl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
