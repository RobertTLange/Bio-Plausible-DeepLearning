\begin{thebibliography}{5}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bartunov et~al.(2018)Bartunov, Santoro, Richards, Marris, Hinton, and
  Lillicrap]{bartunov2018}
Sergey Bartunov, Adam Santoro, Blake Richards, Luke Marris, Geoffrey~E Hinton,
  and Timothy Lillicrap.
\newblock Assessing the scalability of biologically-motivated deep learning
  algorithms and architectures.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  9389--9399, 2018.

\bibitem[Guerguiev et~al.(2017)Guerguiev, Lillicrap, and
  Richards]{guerguiev2017}
Jordan Guerguiev, Timothy~P Lillicrap, and Blake~A Richards.
\newblock Towards deep learning with segregated dendrites.
\newblock \emph{ELife}, 6:\penalty0 e22901, 2017.

\bibitem[Lillicrap et~al.(2016)Lillicrap, Cownden, Tweed, and
  Akerman]{lillicrap2016}
Timothy~P Lillicrap, Daniel Cownden, Douglas~B Tweed, and Colin~J Akerman.
\newblock Random synaptic feedback weights support error backpropagation for
  deep learning.
\newblock \emph{Nature communications}, 7:\penalty0 13276, 2016.

\bibitem[Rumelhart et~al.(1986)Rumelhart, Hinton, and Williams]{rumelhart1986}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning representations by back-propagating errors.
\newblock \emph{Nature}, 323\penalty0 (6088):\penalty0 533, 1986.

\bibitem[Sacramento et~al.(2018)Sacramento, Costa, Bengio, and
  Senn]{sacramento2018}
Jo{\~a}o Sacramento, Rui~Ponte Costa, Yoshua Bengio, and Walter Senn.
\newblock Dendritic cortical microcircuits approximate the backpropagation
  algorithm.
\newblock In \emph{Advances in Neural Information Processing Systems}, pages
  8735--8746, 2018.

\end{thebibliography}
