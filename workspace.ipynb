{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from logger import Logger\n",
    "\n",
    "# Import Network Architectures\n",
    "from DNN import DNN, train_dnn_model\n",
    "from CNN import CNN, train_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: Local CPU\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Torch Device: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Torch Device: Local CPU\")\n",
    "\n",
    "# Define batchsize for data-loading\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CIFAR10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data', \n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),  \n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data', \n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feedforward Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=500, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=500, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Feedforward Neural Network Parameters\n",
    "h_sizes = [784, 500]\n",
    "out_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "dnn_model = DNN(h_sizes, out_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.4428, Train Acc: 0.83, Test Acc: 0.90\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2129, Train Acc: 0.94, Test Acc: 0.93\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2204, Train Acc: 0.92, Test Acc: 0.94\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1562, Train Acc: 0.93, Test Acc: 0.94\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1789, Train Acc: 0.94, Test Acc: 0.95\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1273, Train Acc: 0.96, Test Acc: 0.96\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1527, Train Acc: 0.94, Test Acc: 0.96\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0656, Train Acc: 0.97, Test Acc: 0.96\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0482, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1163, Train Acc: 0.96, Test Acc: 0.97\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1228, Train Acc: 0.97, Test Acc: 0.97\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0571, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0403, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [3/5], Step [200/600], Loss: 0.1210, Train Acc: 0.96, Test Acc: 0.97\n",
      "Epoch [3/5], Step [300/600], Loss: 0.1137, Train Acc: 0.97, Test Acc: 0.97\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0892, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0420, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0621, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0363, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1273, Train Acc: 0.94, Test Acc: 0.97\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0299, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0118, Train Acc: 1.00, Test Acc: 0.97\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0391, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0477, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0300, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0366, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0733, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0541, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0139, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0663, Train Acc: 0.98, Test Acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "train_dnn_model(dnn_model, num_epochs,\n",
    "                train_loader, test_loader,\n",
    "                device, optimizer, criterion,\n",
    "                model_fname =\"models/mnist_dnn.ckpt\",\n",
    "                verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "ReLU()\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "Linear(in_features=1568, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# ConvNet Parameters\n",
    "ch_sizes = [1, 16, 32]\n",
    "k_sizes = [5, 5]\n",
    "stride = 1\n",
    "padding = 2\n",
    "out_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.1153, Train Acc: 0.97, Test Acc: 0.95\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0808, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1376, Train Acc: 0.96, Test Acc: 0.98\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0814, Train Acc: 0.97, Test Acc: 0.98\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0426, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0515, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1729, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0349, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0582, Train Acc: 0.98, Test Acc: 0.99\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1028, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0342, Train Acc: 0.98, Test Acc: 0.99\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0109, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0645, Train Acc: 0.97, Test Acc: 0.98\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0388, Train Acc: 0.98, Test Acc: 0.99\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0114, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0196, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0378, Train Acc: 0.98, Test Acc: 0.99\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0360, Train Acc: 0.99, Test Acc: 0.99\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0129, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0169, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0571, Train Acc: 0.99, Test Acc: 0.99\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0137, Train Acc: 0.99, Test Acc: 0.99\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0871, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0277, Train Acc: 0.99, Test Acc: 0.99\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0112, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0047, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0140, Train Acc: 1.00, Test Acc: 0.99\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0080, Train Acc: 1.00, Test Acc: 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dffff53645a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mmodel_fname\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"models/temp_model_cnn.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                 verbose=True, logging=True)\n\u001b[0m",
      "\u001b[0;32m/Users/rtl/Dropbox/PHD_ECN/COURSES/WiSe_2018_Models_of_Neural_Systems/PROJECT/CODE/CNN.py\u001b[0m in \u001b[0;36mtrain_cnn_model\u001b[0;34m(model, num_epochs, train_loader, test_loader, device, optimizer, criterion, model_fname, verbose, logging)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rtl/anaconda2/envs/mns-project/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rtl/anaconda2/envs/mns-project/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cnn_model(cnn_model, num_epochs,\n",
    "                train_loader, test_loader,\n",
    "                device, optimizer, criterion,\n",
    "                model_fname =\"models/temp_model_cnn.ckpt\",\n",
    "                verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (mns-project)",
   "language": "python",
   "name": "mns-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
