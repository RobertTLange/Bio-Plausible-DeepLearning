{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Network Architectures\n",
    "from DNN import DNN, train_dnn_model\n",
    "from CNN import CNN, train_cnn_model\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from helpers import *\n",
    "from logger import get_latest_log_fname, process_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: Local CPU\n",
      "Deleted Old Files in Existing Log Directory\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Torch Device: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Torch Device: Local CPU\")\n",
    "    \n",
    "# Remove files in log dir\n",
    "log_dir = os.getcwd() + \"/logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(directory)\n",
    "    print(\"Created New Log Directory\")\n",
    "else:\n",
    "    filelist = [ f for f in os.listdir(log_dir) if f.endswith(\".bak\") ]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(mydir, f))\n",
    "    print(\"Deleted Old Files in Existing Log Directory\")\n",
    "\n",
    "# Define batchsize for data-loading\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data', \n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),  \n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../../data', \n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feedforward Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=500, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=500, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Feedforward Neural Network Parameters\n",
    "h_sizes = [784, 500]\n",
    "out_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "dnn_model = DNN(h_sizes, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3280, Train Acc: 0.94, Test Acc: 0.90\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2818, Train Acc: 0.93, Test Acc: 0.93\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1854, Train Acc: 0.94, Test Acc: 0.94\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2366, Train Acc: 0.93, Test Acc: 0.95\n",
      "Epoch [1/5], Step [500/600], Loss: 0.2469, Train Acc: 0.93, Test Acc: 0.95\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1283, Train Acc: 0.98, Test Acc: 0.96\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1042, Train Acc: 0.97, Test Acc: 0.96\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0833, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1355, Train Acc: 0.95, Test Acc: 0.97\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1126, Train Acc: 0.95, Test Acc: 0.97\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0444, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1419, Train Acc: 0.96, Test Acc: 0.97\n",
      "Epoch [3/5], Step [100/600], Loss: 0.1147, Train Acc: 0.97, Test Acc: 0.97\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0742, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0802, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0544, Train Acc: 0.97, Test Acc: 0.97\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0609, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0742, Train Acc: 0.98, Test Acc: 0.97\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0570, Train Acc: 0.99, Test Acc: 0.97\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0232, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0376, Train Acc: 0.99, Test Acc: 0.98\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0309, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [4/5], Step [500/600], Loss: 0.1531, Train Acc: 0.94, Test Acc: 0.98\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0290, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0487, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0293, Train Acc: 0.98, Test Acc: 0.98\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0584, Train Acc: 0.97, Test Acc: 0.98\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0144, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0110, Train Acc: 1.00, Test Acc: 0.98\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0267, Train Acc: 0.98, Test Acc: 0.98\n"
     ]
    }
   ],
   "source": [
    "train_dnn_model(dnn_model, num_epochs,\n",
    "                train_loader, test_loader,\n",
    "                device, optimizer, criterion,\n",
    "                model_fname =\"models/mnist_dnn.ckpt\",\n",
    "                verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fname = get_latest_log_fname(log_dir)\n",
    "its, loss, train_acc, test_acc = process_logger(log_fname)\n",
    "plot_learning(iterations, train_acc, test_acc, loss, \"DNN - Learning Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNet Parameters\n",
    "ch_sizes = [1, 16, 32]\n",
    "k_sizes = [5, 5]\n",
    "stride = 1\n",
    "padding = 2\n",
    "out_size = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnn_model(cnn_model, num_epochs,\n",
    "                train_loader, test_loader,\n",
    "                device, optimizer, criterion,\n",
    "                model_fname =\"models/temp_model_cnn.ckpt\",\n",
    "                verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guergiev et al (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (mns-project)",
   "language": "python",
   "name": "mns-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
