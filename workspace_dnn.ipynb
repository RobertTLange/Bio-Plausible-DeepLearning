{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNS - Biological Plausible Deep Learning\n",
    "## Simple Backprop Baselines (DNNs and CNNs)\n",
    "\n",
    "#### 1. Data Setup - Download and Loading-In\n",
    "#### 2. PyTorch DNNs with Bayesian Optimization\n",
    "#### 3. PyTorch CNNs with Bayesian Optimization\n",
    "#### 4. Run Example 784/3072 - 500 - 10 Architecture on all Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import tf for tensorboard monitoring of training\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Network Architectures\n",
    "from models.DNN import DNN, eval_dnn\n",
    "from models.CNN import CNN, eval_cnn\n",
    "\n",
    "# Import log-helper/learning plot functions\n",
    "from utils.helpers import *\n",
    "from utils.logger import *\n",
    "\n",
    "# Import Bayesian Optimization Module\n",
    "from utils.bayesian_opt import BO_NN\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Device: Local CPU\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Torch Device: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Torch Device: Local CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Old TF/TensorBoard Log Files in Existing Log Directory\n"
     ]
    }
   ],
   "source": [
    "# Create all necessary directory if non-existent\n",
    "global data_dir\n",
    "data_dir = os.getcwd() +\"/data\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    print(\"Created New Data Directory\")\n",
    "\n",
    "# Create Log Directory or remove tensorboard log files in log dir\n",
    "log_dir = os.getcwd() + \"/logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    print(\"Created New Log Directory\")\n",
    "else:\n",
    "    filelist = [ f for f in os.listdir(log_dir) if f.startswith(\"events\")]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(log_dir, f))\n",
    "    print(\"Deleted Old TF/TensorBoard Log Files in Existing Log Directory\")\n",
    "    \n",
    "models_dir = os.getcwd() + \"/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download, Import and Plot Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download of MNIST needed.\n",
      "No download of Fashion-MNIST needed.\n",
      "No download of CIFAR-10 needed.\n"
     ]
    }
   ],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "X_mnist, y_mnist = get_data(num_samples=70000, dataset=\"mnist\")\n",
    "# MNIST dataset\n",
    "X_fashion, y_fashion = get_data(num_samples=70000, dataset=\"fashion\")\n",
    "# MNIST dataset\n",
    "X_cifar10, y_cifar10 = get_data(num_samples=60000, dataset=\"cifar10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Feedforward Neural Net\n",
    "\n",
    "### Run a Simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Define batchsize for data-loading/Epochs for training\n",
    "batch_size = 100\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersize and Logging directory\n",
    "dnn_model = DNN(h_sizes=[784, 500], out_size=10)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train| epoch  1| batch 20000/41996| acc: 0.9975| loss: 0.0090| time: 0.27\n",
      "valid| epoch  1| batch 20000/41996| acc: 0.9760| loss: 0.0888| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 40000/41996| acc: 0.9972| loss: 0.0101| time: 0.28\n",
      "valid| epoch  1| batch 40000/41996| acc: 0.9747| loss: 0.0933| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 20000/41996| acc: 0.9977| loss: 0.0085| time: 0.27\n",
      "valid| epoch  2| batch 20000/41996| acc: 0.9766| loss: 0.0918| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 40000/41996| acc: 0.9952| loss: 0.0146| time: 0.28\n",
      "valid| epoch  2| batch 40000/41996| acc: 0.9741| loss: 0.0959| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 20000/41996| acc: 0.9986| loss: 0.0060| time: 0.28\n",
      "valid| epoch  3| batch 20000/41996| acc: 0.9772| loss: 0.0906| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 40000/41996| acc: 0.9948| loss: 0.0161| time: 0.28\n",
      "valid| epoch  3| batch 40000/41996| acc: 0.9739| loss: 0.1061| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 20000/41996| acc: 0.9978| loss: 0.0080| time: 0.27\n",
      "valid| epoch  4| batch 20000/41996| acc: 0.9751| loss: 0.0970| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 40000/41996| acc: 0.9983| loss: 0.0064| time: 0.29\n",
      "valid| epoch  4| batch 40000/41996| acc: 0.9760| loss: 0.0987| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 20000/41996| acc: 0.9986| loss: 0.0059| time: 0.32\n",
      "valid| epoch  5| batch 20000/41996| acc: 0.9767| loss: 0.0948| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 40000/41996| acc: 0.9974| loss: 0.0080| time: 0.31\n",
      "valid| epoch  5| batch 40000/41996| acc: 0.9750| loss: 0.1046| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 20000/41996| acc: 0.9988| loss: 0.0043| time: 0.29\n",
      "valid| epoch  6| batch 20000/41996| acc: 0.9756| loss: 0.1015| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 40000/41996| acc: 0.9979| loss: 0.0071| time: 0.28\n",
      "valid| epoch  6| batch 40000/41996| acc: 0.9772| loss: 0.1032| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 20000/41996| acc: 0.9984| loss: 0.0059| time: 0.28\n",
      "valid| epoch  7| batch 20000/41996| acc: 0.9758| loss: 0.1061| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 40000/41996| acc: 0.9978| loss: 0.0066| time: 0.28\n",
      "valid| epoch  7| batch 40000/41996| acc: 0.9753| loss: 0.1099| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 20000/41996| acc: 0.9979| loss: 0.0065| time: 0.26\n",
      "valid| epoch  8| batch 20000/41996| acc: 0.9763| loss: 0.1049| time: 0.07\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 40000/41996| acc: 0.9993| loss: 0.0028| time: 0.29\n",
      "valid| epoch  8| batch 40000/41996| acc: 0.9771| loss: 0.0996| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 20000/41996| acc: 0.9988| loss: 0.0038| time: 0.30\n",
      "valid| epoch  9| batch 20000/41996| acc: 0.9755| loss: 0.1086| time: 0.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 40000/41996| acc: 0.9997| loss: 0.0019| time: 0.29\n",
      "valid| epoch  9| batch 40000/41996| acc: 0.9780| loss: 0.0995| time: 0.08\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 20000/41996| acc: 0.9989| loss: 0.0041| time: 0.31\n",
      "valid| epoch 10| batch 20000/41996| acc: 0.9752| loss: 0.1147| time: 0.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 40000/41996| acc: 0.9997| loss: 0.0015| time: 0.27\n",
      "valid| epoch 10| batch 40000/41996| acc: 0.9796| loss: 0.1015| time: 0.07\n",
      "-------------------------------------------------------------------------\n",
      "Test Accuracy: 0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\"dnn\", dnn_model, num_epochs,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 20000,\n",
    "                    model_fname =\"temp_model_dnn_mnist\",\n",
    "                    verbose=True, logging=True)\n",
    "\n",
    "# Get test error\n",
    "score = get_test_error(\"dnn\", device, model, X_test, y_test)\n",
    "print(\"Test Accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cross Validation Accuracy for all 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: mnist\n",
      "Batchsize: 100\n",
      "Learning Rate: 0.001\n",
      "Architecture of Cross-Validated Network:\n",
      "\t Layer 0: 784 Units\n",
      "\t Layer 1: 500 Units\n",
      "Cross-Validation Score Fold 1: 0.9694892012341446\n",
      "Cross-Validation Score Fold 2: 0.9687995542793468\n",
      "Cross-Validation Score Fold 3: 0.975011786892975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9711001808021554"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 3-fold cross-validation on specific architecture for MNIST\n",
    "eval_dnn(\"mnist\", batch_size, learning_rate,\n",
    "         num_layers=1, h_l_1=500,\n",
    "         num_epochs=5, k_fold=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: fashion\n",
      "Batchsize: 100\n",
      "Learning Rate: 0.001\n",
      "Architecture of Cross-Validated Network:\n",
      "\t Layer 0: 784 Units\n",
      "\t Layer 1: 500 Units\n",
      "Cross-Validation Score Fold 1: 0.876092544987\n",
      "Cross-Validation Score Fold 2: 0.877111015859\n",
      "Cross-Validation Score Fold 3: 0.758551221603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8372515941498805"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 3-fold cross-validation on specific architecture for Fashion-MNIST\n",
    "eval_dnn(\"fashion\", batch_size, learning_rate,\n",
    "         num_layers=1, h_l_1=500,\n",
    "         num_epochs=5, k_fold=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cifar10\n",
      "Batchsize: 100\n",
      "Learning Rate: 0.001\n",
      "Architecture of Cross-Validated Network:\n",
      "\t Layer 0: 3072 Units\n",
      "\t Layer 1: 500 Units\n",
      "Cross-Validation Score Fold 1: 0.4278\n",
      "Cross-Validation Score Fold 2: 0.434\n",
      "Cross-Validation Score Fold 3: 0.40585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 3-fold cross-validation on specific architecture for CIFAR-10\n",
    "eval_dnn(\"cifar10\", batch_size, learning_rate,\n",
    "         num_layers=1, h_l_1=500,\n",
    "         num_epochs=5, k_fold=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Bayesian Optimization on DNN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Search Hyperspace for Bayesian Optimization on DNN architectures\n",
    "hyper_space_dnn = {'batch_size': (10, 500),\n",
    "                   'learning_rate': (0.0001, 0.05),\n",
    "                   'num_layers': (1, 6),\n",
    "                   'h_l_1': (30, 500),\n",
    "                   'h_l_2': (30, 500),\n",
    "                   'h_l_3': (30, 500),\n",
    "                   'h_l_4': (30, 500),\n",
    "                   'h_l_5': (30, 500),\n",
    "                   'h_l_6': (30, 500)}\n",
    "\n",
    "bo_iters = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logging to ./logs/bo_logs_dnn_mnist.json\n",
      "BO iter  1 | cv-acc: 0.9590 | best-acc: 0.9590 | time: 29.70\n",
      "BO iter  2 | cv-acc: 0.9629 | best-acc: 0.9629 | time: 38.18\n",
      "BO iter  3 | cv-acc: 0.9004 | best-acc: 0.9629 | time: 31.98\n",
      "BO iter  4 | cv-acc: 0.1361 | best-acc: 0.9629 | time: 122.09\n",
      "BO iter  5 | cv-acc: 0.9315 | best-acc: 0.9629 | time: 39.83\n",
      "BO iter  6 | cv-acc: 0.5563 | best-acc: 0.9629 | time: 238.18\n",
      "BO iter  7 | cv-acc: 0.8754 | best-acc: 0.9629 | time: 34.68\n",
      "BO iter  8 | cv-acc: 0.9472 | best-acc: 0.9629 | time: 37.67\n",
      "BO iter  9 | cv-acc: 0.8748 | best-acc: 0.9629 | time: 36.25\n",
      "BO iter 10 | cv-acc: 0.9255 | best-acc: 0.9629 | time: 40.50\n",
      "BO iter 11 | cv-acc: 0.9371 | best-acc: 0.9629 | time: 33.72\n",
      "BO iter 12 | cv-acc: 0.6745 | best-acc: 0.9629 | time: 37.56\n",
      "BO iter 13 | cv-acc: 0.9253 | best-acc: 0.9629 | time: 33.46\n",
      "BO iter 14 | cv-acc: 0.9496 | best-acc: 0.9629 | time: 44.18\n",
      "BO iter 15 | cv-acc: 0.9284 | best-acc: 0.9629 | time: 41.98\n",
      "BO iter 16 | cv-acc: 0.9738 | best-acc: 0.9738 | time: 231.82\n",
      "BO iter 17 | cv-acc: 0.9741 | best-acc: 0.9741 | time: 230.70\n",
      "BO iter 18 | cv-acc: 0.9453 | best-acc: 0.9741 | time: 43.87\n",
      "BO iter 19 | cv-acc: 0.9361 | best-acc: 0.9741 | time: 227.48\n",
      "BO iter 20 | cv-acc: 0.9372 | best-acc: 0.9741 | time: 229.59\n",
      "BO iter 21 | cv-acc: 0.9252 | best-acc: 0.9741 | time: 35.29\n",
      "BO iter 22 | cv-acc: 0.9252 | best-acc: 0.9741 | time: 35.97\n",
      "BO iter 23 | cv-acc: 0.8769 | best-acc: 0.9741 | time: 36.85\n",
      "BO iter 24 | cv-acc: 0.9610 | best-acc: 0.9741 | time: 125.39\n",
      "BO iter 25 | cv-acc: 0.9409 | best-acc: 0.9741 | time: 52.10\n",
      "BO iter 26 | cv-acc: 0.9474 | best-acc: 0.9741 | time: 51.63\n",
      "BO iter 27 | cv-acc: 0.0986 | best-acc: 0.9741 | time: 553.48\n",
      "BO iter 28 | cv-acc: 0.8892 | best-acc: 0.9741 | time: 37.26\n",
      "BO iter 29 | cv-acc: 0.9253 | best-acc: 0.9741 | time: 32.41\n",
      "BO iter 30 | cv-acc: 0.9610 | best-acc: 0.9741 | time: 543.09\n",
      "BO iter 31 | cv-acc: 0.9403 | best-acc: 0.9741 | time: 45.21\n",
      "BO iter 32 | cv-acc: 0.8751 | best-acc: 0.9741 | time: 30.30\n",
      "BO iter 33 | cv-acc: 0.9255 | best-acc: 0.9741 | time: 32.70\n",
      "BO iter 34 | cv-acc: 0.9246 | best-acc: 0.9741 | time: 35.12\n",
      "BO iter 35 | cv-acc: 0.9274 | best-acc: 0.9741 | time: 45.65\n",
      "BO iter 36 | cv-acc: 0.9200 | best-acc: 0.9741 | time: 46.93\n",
      "BO iter 37 | cv-acc: 0.9363 | best-acc: 0.9741 | time: 234.68\n",
      "BO iter 38 | cv-acc: 0.9375 | best-acc: 0.9741 | time: 232.51\n",
      "BO iter 39 | cv-acc: 0.9732 | best-acc: 0.9741 | time: 237.07\n",
      "BO iter 40 | cv-acc: 0.9452 | best-acc: 0.9741 | time: 550.78\n",
      "BO iter 41 | cv-acc: 0.9722 | best-acc: 0.9741 | time: 237.74\n",
      "BO iter 42 | cv-acc: 0.9367 | best-acc: 0.9741 | time: 236.17\n",
      "BO iter 43 | cv-acc: 0.9729 | best-acc: 0.9741 | time: 240.00\n",
      "BO iter 44 | cv-acc: 0.9692 | best-acc: 0.9741 | time: 559.10\n",
      "BO iter 45 | cv-acc: 0.9359 | best-acc: 0.9741 | time: 239.32\n",
      "BO iter 46 | cv-acc: 0.9356 | best-acc: 0.9741 | time: 237.92\n",
      "BO iter 47 | cv-acc: 0.9118 | best-acc: 0.9741 | time: 42.94\n",
      "BO iter 48 | cv-acc: 0.9076 | best-acc: 0.9741 | time: 42.31\n",
      "BO iter 49 | cv-acc: 0.9244 | best-acc: 0.9741 | time: 46.57\n",
      "BO iter 50 | cv-acc: 0.9249 | best-acc: 0.9741 | time: 45.37\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN for MNIST\n",
    "opt_log = BO_NN(bo_iters, eval_dnn, \"dnn\", \"mnist\", hyper_space_dnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded previously existing Log with 51 BO iterations.\n",
      "Start Logging to ./logs/bo_logs_dnn_mnist.json\n",
      "BO iter 52 | cv-acc: 0.1011 | best-acc: 0.9741 | time: 1044.87\n",
      "BO iter 53 | cv-acc: 0.9082 | best-acc: 0.9741 | time: 35.74\n",
      "{'target': 0.10114276914982212, 'params': {'batch_size': 10.0, 'h_l_1': 500.0, 'h_l_2': 30.0, 'h_l_3': 30.0, 'h_l_4': 500.0, 'h_l_5': 500.0, 'h_l_6': 500.0, 'learning_rate': 0.05, 'num_layers': 6.0}, 'datetime': {'datetime': '2019-01-13 13:20:45', 'elapsed': 0.0, 'delta': 0.0}}\n",
      "{'target': 0.9082283758251236, 'params': {'batch_size': 10.0, 'h_l_1': 30.0, 'h_l_2': 30.0, 'h_l_3': 30.0, 'h_l_4': 30.0, 'h_l_5': 30.0, 'h_l_6': 500.0, 'learning_rate': 0.0001, 'num_layers': 1.0}, 'datetime': {'datetime': '2019-01-13 13:21:20', 'elapsed': 35.738005, 'delta': 35.738005}}\n",
      "Merged JSON logs - Total iterations: 53\n",
      "Removed temporary log file.\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN for MNIST\n",
    "opt_log = BO_NN(2, eval_dnn, \"dnn\", \"mnist\", hyper_space_dnn,\n",
    "                num_epochs=2, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logging to ./logs/bo_logs_dnn_fashion.json\n",
      "BO iter  1 | cv-acc: 0.8530 | best-acc: 0.8530 | time: 30.22\n",
      "BO iter  2 | cv-acc: 0.8560 | best-acc: 0.8560 | time: 38.44\n",
      "BO iter  3 | cv-acc: 0.6448 | best-acc: 0.8560 | time: 32.25\n",
      "BO iter  4 | cv-acc: 0.8574 | best-acc: 0.8574 | time: 545.27\n",
      "BO iter  5 | cv-acc: 0.2121 | best-acc: 0.8574 | time: 232.47\n",
      "BO iter  6 | cv-acc: 0.8607 | best-acc: 0.8607 | time: 554.57\n",
      "BO iter  7 | cv-acc: 0.7732 | best-acc: 0.8607 | time: 48.55\n",
      "BO iter  8 | cv-acc: 0.8727 | best-acc: 0.8727 | time: 555.34\n",
      "BO iter  9 | cv-acc: 0.7778 | best-acc: 0.8727 | time: 45.31\n",
      "BO iter 10 | cv-acc: 0.8319 | best-acc: 0.8727 | time: 35.15\n",
      "BO iter 11 | cv-acc: 0.8430 | best-acc: 0.8727 | time: 34.44\n",
      "BO iter 12 | cv-acc: 0.1983 | best-acc: 0.8727 | time: 228.98\n",
      "BO iter 13 | cv-acc: 0.8796 | best-acc: 0.8796 | time: 552.15\n",
      "BO iter 14 | cv-acc: 0.8537 | best-acc: 0.8796 | time: 547.69\n",
      "BO iter 15 | cv-acc: 0.8263 | best-acc: 0.8796 | time: 40.06\n",
      "BO iter 16 | cv-acc: 0.7475 | best-acc: 0.8796 | time: 36.74\n",
      "BO iter 17 | cv-acc: 0.8265 | best-acc: 0.8796 | time: 46.92\n",
      "BO iter 18 | cv-acc: 0.8757 | best-acc: 0.8796 | time: 545.47\n",
      "BO iter 19 | cv-acc: 0.8664 | best-acc: 0.8796 | time: 546.57\n",
      "BO iter 20 | cv-acc: 0.8540 | best-acc: 0.8796 | time: 543.36\n",
      "BO iter 21 | cv-acc: 0.8464 | best-acc: 0.8796 | time: 546.13\n",
      "BO iter 22 | cv-acc: 0.8416 | best-acc: 0.8796 | time: 46.38\n",
      "BO iter 23 | cv-acc: 0.8126 | best-acc: 0.8796 | time: 45.55\n",
      "BO iter 24 | cv-acc: 0.3274 | best-acc: 0.8796 | time: 52.02\n",
      "BO iter 25 | cv-acc: 0.8113 | best-acc: 0.8796 | time: 38.89\n",
      "BO iter 26 | cv-acc: 0.8480 | best-acc: 0.8796 | time: 544.00\n",
      "BO iter 27 | cv-acc: 0.8080 | best-acc: 0.8796 | time: 39.35\n",
      "BO iter 28 | cv-acc: 0.8610 | best-acc: 0.8796 | time: 543.28\n",
      "BO iter 29 | cv-acc: 0.7266 | best-acc: 0.8796 | time: 35.98\n",
      "BO iter 30 | cv-acc: 0.8747 | best-acc: 0.8796 | time: 231.45\n",
      "BO iter 31 | cv-acc: 0.8508 | best-acc: 0.8796 | time: 546.96\n",
      "BO iter 32 | cv-acc: 0.8241 | best-acc: 0.8796 | time: 42.29\n",
      "BO iter 33 | cv-acc: 0.7838 | best-acc: 0.8796 | time: 35.20\n",
      "BO iter 34 | cv-acc: 0.8640 | best-acc: 0.8796 | time: 235.24\n",
      "BO iter 35 | cv-acc: 0.7888 | best-acc: 0.8796 | time: 45.44\n",
      "BO iter 36 | cv-acc: 0.7825 | best-acc: 0.8796 | time: 41.41\n",
      "BO iter 37 | cv-acc: 0.8641 | best-acc: 0.8796 | time: 243.01\n",
      "BO iter 38 | cv-acc: 0.8385 | best-acc: 0.8796 | time: 550.44\n",
      "BO iter 39 | cv-acc: 0.8412 | best-acc: 0.8796 | time: 53.14\n",
      "BO iter 40 | cv-acc: 0.8436 | best-acc: 0.8796 | time: 43.35\n",
      "BO iter 41 | cv-acc: 0.8733 | best-acc: 0.8796 | time: 244.62\n",
      "BO iter 42 | cv-acc: 0.1000 | best-acc: 0.8796 | time: 51.03\n",
      "BO iter 43 | cv-acc: 0.8420 | best-acc: 0.8796 | time: 543.73\n",
      "BO iter 44 | cv-acc: 0.8295 | best-acc: 0.8796 | time: 48.20\n",
      "BO iter 45 | cv-acc: 0.7647 | best-acc: 0.8796 | time: 41.54\n",
      "BO iter 46 | cv-acc: 0.8493 | best-acc: 0.8796 | time: 554.30\n",
      "BO iter 47 | cv-acc: 0.1000 | best-acc: 0.8796 | time: 549.32\n",
      "BO iter 48 | cv-acc: 0.8460 | best-acc: 0.8796 | time: 546.76\n",
      "BO iter 49 | cv-acc: 0.7955 | best-acc: 0.8796 | time: 41.34\n",
      "BO iter 50 | cv-acc: 0.8599 | best-acc: 0.8796 | time: 546.03\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN for Fashion-MNIST\n",
    "opt_log = BO_NN(bo_iters, eval_dnn, \"dnn\", \"fashion\", hyper_space_dnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Logging to ./logs/bo_logs_dnn_cifar10.json\n",
      "BO iter  1 | cv-acc: 0.1000 | best-acc: 0.1000 | time: 42.11\n",
      "BO iter  2 | cv-acc: 0.2539 | best-acc: 0.2539 | time: 44.48\n",
      "BO iter  3 | cv-acc: 0.1000 | best-acc: 0.2539 | time: 32.56\n",
      "BO iter  4 | cv-acc: 0.4222 | best-acc: 0.4222 | time: 491.41\n",
      "BO iter  5 | cv-acc: 0.4090 | best-acc: 0.4222 | time: 483.14\n",
      "BO iter  6 | cv-acc: 0.4132 | best-acc: 0.4222 | time: 491.96\n",
      "BO iter  7 | cv-acc: 0.1000 | best-acc: 0.4222 | time: 216.67\n",
      "BO iter  8 | cv-acc: 0.4533 | best-acc: 0.4533 | time: 512.72\n",
      "BO iter  9 | cv-acc: 0.3673 | best-acc: 0.4533 | time: 56.29\n",
      "BO iter 10 | cv-acc: 0.3913 | best-acc: 0.4533 | time: 486.15\n",
      "BO iter 11 | cv-acc: 0.4206 | best-acc: 0.4533 | time: 488.19\n",
      "BO iter 12 | cv-acc: 0.1000 | best-acc: 0.4533 | time: 288.32\n",
      "BO iter 13 | cv-acc: 0.3621 | best-acc: 0.4533 | time: 62.50\n",
      "BO iter 14 | cv-acc: 0.4229 | best-acc: 0.4533 | time: 491.41\n",
      "BO iter 15 | cv-acc: 0.3767 | best-acc: 0.4533 | time: 56.58\n",
      "BO iter 16 | cv-acc: 0.3145 | best-acc: 0.4533 | time: 48.89\n",
      "BO iter 17 | cv-acc: 0.4183 | best-acc: 0.4533 | time: 486.25\n",
      "BO iter 18 | cv-acc: 0.4219 | best-acc: 0.4533 | time: 483.73\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN for CIFAR-10\n",
    "opt_log = BO_NN(bo_iters, eval_dnn, \"dnn\", \"cifar10\", hyper_space_dnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# ConvNet Parameters\n",
    "batch_size = 100\n",
    "ch_sizes = [1, 16, 32]\n",
    "k_sizes = [5, 5]\n",
    "stride = 1\n",
    "padding = 2\n",
    "out_size = 10\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(\"cnn\", cnn_model, num_epochs,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion, log_freq=10000,\n",
    "                    model_fname =\"models/temp_model_cnn.ckpt\",\n",
    "                    verbose=False, logging=True)\n",
    "\n",
    "# Get test error\n",
    "score = get_test_error(\"cnn\", device, model, X_test, y_test)\n",
    "print(\"Test Accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_fname = get_latest_log_fname(log_dir)\n",
    "its, train_loss, val_loss, train_acc, val_acc = process_logger(log_fname)\n",
    "plot_learning(its, train_acc, val_acc, train_loss, val_loss, \"CNN - Learning Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3-fold cross-validation on specific architecture\n",
    "eval_cnn(batch_size, learning_rate, num_layers=2,\n",
    "         ch_1=16, ch_2=32, k_1=5, k_2=5,\n",
    "         stride=1, padding=2,\n",
    "         k_fold=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN\n",
    "hyper_space_cnn = {'batch_size': (10, 500),\n",
    "                   'learning_rate': (0.0001, 0.05),\n",
    "                   'num_layers': (1, 5),\n",
    "                   'ch_1': (3, 64),\n",
    "                   'ch_2': (3, 64),\n",
    "                   'ch_3': (3, 64),\n",
    "                   'ch_4': (3, 64),\n",
    "                   'ch_5': (3, 64),\n",
    "                   'k_1': (2, 10),\n",
    "                   'k_2': (2, 10),\n",
    "                   'k_3': (2, 10),\n",
    "                   'k_4': (2, 10),\n",
    "                   'k_5': (2, 10),\n",
    "                   'stride': (1, 3),\n",
    "                   'padding': (1, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on CNN for MNIST\n",
    "opt_log = BO_NN(bo_iters, eval_cnn, \"cnn\", \"mnist\", hyper_space_cnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on CNN for Fashion-MNIST\n",
    "opt_log = BO_NN(bo_iters, eval_cnn, \"cnn\", \"fashion\", hyper_space_cnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Bayesian Optimization (UCB-Acquisition Fct) on DNN for CIFAR-10\n",
    "opt_log = BO_NN(bo_iters, eval_cnn, \"cnn\", \"cifar10\", hyper_space_dnn,\n",
    "                num_epochs=10, k_fold=3, logging=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Full Models (10 Epochs, Logging every 5000 eps and all Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9202f27e3ad1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                     \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_mnist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                     random_state=0)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define batchsize for data-loading/Epochs for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Define batchsize for data-loading/Epochs for training\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate the model with layersize and Logging directory\n",
    "dnn_model = DNN(h_sizes=[784, 500], out_size=10)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"dnn\", dnn_model, 10,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 5000,\n",
    "                    model_fname =\"temp_model_dnn_mnist\",\n",
    "                    verbose=True, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fashion, y_fashion,\n",
    "                                                    stratify=y_fashion,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model with layersize and Logging directory\n",
    "dnn_model = DNN(h_sizes=[784, 500], out_size=10)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"dnn\", dnn_model, 10,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 5000,\n",
    "                    model_fname =\"temp_model_dnn_fashion\",\n",
    "                    verbose=False, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_cifar10, y_cifar10,\n",
    "                                                    stratify=y_cifar10,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model with layersize and Logging directory\n",
    "dnn_model = DNN(h_sizes=[3072, 500], out_size=10)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"dnn\", dnn_model, 10,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion,\n",
    "                    log_freq = 5000,\n",
    "                    model_fname =\"temp_model_dnn_cifar\",\n",
    "                    verbose=False, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNet Parameters\n",
    "batch_size = 100\n",
    "ch_sizes = [1, 16, 32]\n",
    "k_sizes = [5, 5]\n",
    "stride = 1\n",
    "padding = 2\n",
    "out_size = 10\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train| epoch  1| batch 5000/41996| acc: 0.9016| loss: 0.4435| time: 42.28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1326565cbf73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mmodel_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mnist_cnn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     verbose=True, logging=True)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Get test error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/Bio-DRL/CODE/utils/helpers.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model_type, model, num_epochs, X, y, batch_size, device, optimizer, criterion, log_freq, model_fname, verbose, logging)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 valid_out = valid_step(model_type, model, X_valid, y_valid,\n\u001b[1;32m    349\u001b[0m                                        \u001b[0mbatch_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                                        device=device, criterion=criterion)\n\u001b[0m\u001b[1;32m    351\u001b[0m                 valid_loss, valid_acc = report(verbose, y=y_valid, batch_cur=batch_cur,\n\u001b[1;32m    352\u001b[0m                                                \u001b[0mbatch_total\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/Bio-DRL/CODE/utils/helpers.py\u001b[0m in \u001b[0;36mvalid_step\u001b[0;34m(model_type, model, X_valid, y_valid, batch_s, device, criterion)\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/Bio-DRL/CODE/models/CNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    146\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    147\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# type: (Tensor, BroadcastingList2[int], Optional[BroadcastingList2[int]], BroadcastingList2[int], BroadcastingList2[int], bool, bool) -> Tensor  # noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     return max_pool2d_with_indices(\n\u001b[0;32m--> 425\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)[0]\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m max_pool2d = torch._jit_internal.boolean_dispatch(\n",
      "\u001b[0;32m~/anaconda2/envs/BioDL/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmax_pool2d_with_indices\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0m_stride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d_with_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_mnist, y_mnist,\n",
    "                                                    stratify=y_mnist,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"cnn\", cnn_model, num_epochs,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion, log_freq=5000,\n",
    "                    model_fname = \"mnist_cnn\",\n",
    "                    verbose=True, logging=True)\n",
    "\n",
    "# Get test error\n",
    "score = get_test_error(\"cnn\", device, model, X_test, y_test)\n",
    "print(\"Test Accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train| epoch  1| batch 5000/41997| acc: 0.7750| loss: 0.6382| time: 31.39\n",
      "valid| epoch  1| batch 5000/41997| acc: 0.7733| loss: 0.6767| time: 6.80\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 10000/41997| acc: 0.8282| loss: 0.4743| time: 48.27\n",
      "valid| epoch  1| batch 10000/41997| acc: 0.8277| loss: 0.4760| time: 5.10\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 15000/41997| acc: 0.8434| loss: 0.4381| time: 48.98\n",
      "valid| epoch  1| batch 15000/41997| acc: 0.8413| loss: 0.4422| time: 5.15\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 20000/41997| acc: 0.8601| loss: 0.3918| time: 45.16\n",
      "valid| epoch  1| batch 20000/41997| acc: 0.8598| loss: 0.4008| time: 5.20\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 25000/41997| acc: 0.8632| loss: 0.3862| time: 44.51\n",
      "valid| epoch  1| batch 25000/41997| acc: 0.8619| loss: 0.3989| time: 5.04\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 30000/41997| acc: 0.8669| loss: 0.3659| time: 40.76\n",
      "valid| epoch  1| batch 30000/41997| acc: 0.8648| loss: 0.3774| time: 5.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 35000/41997| acc: 0.8648| loss: 0.3729| time: 46.34\n",
      "valid| epoch  1| batch 35000/41997| acc: 0.8564| loss: 0.3895| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 40000/41997| acc: 0.8797| loss: 0.3392| time: 46.08\n",
      "valid| epoch  1| batch 40000/41997| acc: 0.8738| loss: 0.3548| time: 5.33\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 5000/41997| acc: 0.8727| loss: 0.3609| time: 48.33\n",
      "valid| epoch  2| batch 5000/41997| acc: 0.8675| loss: 0.3728| time: 5.06\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 10000/41997| acc: 0.8793| loss: 0.3433| time: 45.72\n",
      "valid| epoch  2| batch 10000/41997| acc: 0.8727| loss: 0.3577| time: 5.21\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 15000/41997| acc: 0.8865| loss: 0.3187| time: 48.74\n",
      "valid| epoch  2| batch 15000/41997| acc: 0.8817| loss: 0.3344| time: 6.43\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 20000/41997| acc: 0.8819| loss: 0.3269| time: 44.55\n",
      "valid| epoch  2| batch 20000/41997| acc: 0.8727| loss: 0.3472| time: 5.19\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 25000/41997| acc: 0.8941| loss: 0.3035| time: 44.26\n",
      "valid| epoch  2| batch 25000/41997| acc: 0.8888| loss: 0.3229| time: 5.07\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 30000/41997| acc: 0.8911| loss: 0.2990| time: 46.71\n",
      "valid| epoch  2| batch 30000/41997| acc: 0.8853| loss: 0.3192| time: 5.28\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 35000/41997| acc: 0.8891| loss: 0.3047| time: 44.20\n",
      "valid| epoch  2| batch 35000/41997| acc: 0.8815| loss: 0.3263| time: 5.13\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 40000/41997| acc: 0.8971| loss: 0.2907| time: 42.32\n",
      "valid| epoch  2| batch 40000/41997| acc: 0.8895| loss: 0.3130| time: 5.23\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 5000/41997| acc: 0.8894| loss: 0.3098| time: 51.21\n",
      "valid| epoch  3| batch 5000/41997| acc: 0.8778| loss: 0.3329| time: 5.33\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 10000/41997| acc: 0.8952| loss: 0.3011| time: 46.47\n",
      "valid| epoch  3| batch 10000/41997| acc: 0.8840| loss: 0.3241| time: 5.22\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 15000/41997| acc: 0.9011| loss: 0.2789| time: 44.37\n",
      "valid| epoch  3| batch 15000/41997| acc: 0.8932| loss: 0.3018| time: 5.32\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 20000/41997| acc: 0.8933| loss: 0.2927| time: 43.18\n",
      "valid| epoch  3| batch 20000/41997| acc: 0.8824| loss: 0.3203| time: 5.15\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 25000/41997| acc: 0.9069| loss: 0.2678| time: 46.28\n",
      "valid| epoch  3| batch 25000/41997| acc: 0.8945| loss: 0.2948| time: 5.05\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 30000/41997| acc: 0.8971| loss: 0.2785| time: 45.26\n",
      "valid| epoch  3| batch 30000/41997| acc: 0.8847| loss: 0.3087| time: 5.40\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 35000/41997| acc: 0.9000| loss: 0.2744| time: 44.55\n",
      "valid| epoch  3| batch 35000/41997| acc: 0.8896| loss: 0.3052| time: 5.24\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  3| batch 40000/41997| acc: 0.9042| loss: 0.2675| time: 43.58\n",
      "valid| epoch  3| batch 40000/41997| acc: 0.8974| loss: 0.2950| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 5000/41997| acc: 0.9004| loss: 0.2797| time: 50.80\n",
      "valid| epoch  4| batch 5000/41997| acc: 0.8877| loss: 0.3123| time: 5.32\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 10000/41997| acc: 0.9037| loss: 0.2763| time: 43.86\n",
      "valid| epoch  4| batch 10000/41997| acc: 0.8909| loss: 0.3080| time: 5.11\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 15000/41997| acc: 0.9100| loss: 0.2529| time: 48.53\n",
      "valid| epoch  4| batch 15000/41997| acc: 0.8991| loss: 0.2841| time: 5.19\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 20000/41997| acc: 0.9031| loss: 0.2681| time: 44.74\n",
      "valid| epoch  4| batch 20000/41997| acc: 0.8877| loss: 0.3024| time: 5.15\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 25000/41997| acc: 0.9147| loss: 0.2450| time: 45.14\n",
      "valid| epoch  4| batch 25000/41997| acc: 0.9003| loss: 0.2803| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 30000/41997| acc: 0.9024| loss: 0.2634| time: 42.32\n",
      "valid| epoch  4| batch 30000/41997| acc: 0.8854| loss: 0.3011| time: 5.10\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 35000/41997| acc: 0.9061| loss: 0.2574| time: 48.48\n",
      "valid| epoch  4| batch 35000/41997| acc: 0.8940| loss: 0.2964| time: 7.03\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  4| batch 40000/41997| acc: 0.9114| loss: 0.2469| time: 43.25\n",
      "valid| epoch  4| batch 40000/41997| acc: 0.9015| loss: 0.2809| time: 5.06\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 5000/41997| acc: 0.9077| loss: 0.2594| time: 50.55\n",
      "valid| epoch  5| batch 5000/41997| acc: 0.8911| loss: 0.2997| time: 5.25\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 10000/41997| acc: 0.9079| loss: 0.2589| time: 42.31\n",
      "valid| epoch  5| batch 10000/41997| acc: 0.8953| loss: 0.2990| time: 5.01\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 15000/41997| acc: 0.9171| loss: 0.2341| time: 44.34\n",
      "valid| epoch  5| batch 15000/41997| acc: 0.9032| loss: 0.2729| time: 5.09\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 20000/41997| acc: 0.9107| loss: 0.2483| time: 44.78\n",
      "valid| epoch  5| batch 20000/41997| acc: 0.8920| loss: 0.2904| time: 7.91\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 25000/41997| acc: 0.9206| loss: 0.2276| time: 42.09\n",
      "valid| epoch  5| batch 25000/41997| acc: 0.9040| loss: 0.2704| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 30000/41997| acc: 0.9083| loss: 0.2479| time: 41.44\n",
      "valid| epoch  5| batch 30000/41997| acc: 0.8902| loss: 0.2941| time: 5.04\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 35000/41997| acc: 0.9115| loss: 0.2437| time: 43.42\n",
      "valid| epoch  5| batch 35000/41997| acc: 0.8956| loss: 0.2894| time: 5.59\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  5| batch 40000/41997| acc: 0.9165| loss: 0.2314| time: 42.68\n",
      "valid| epoch  5| batch 40000/41997| acc: 0.9049| loss: 0.2733| time: 5.25\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 5000/41997| acc: 0.9124| loss: 0.2443| time: 49.59\n",
      "valid| epoch  6| batch 5000/41997| acc: 0.8942| loss: 0.2932| time: 5.31\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 10000/41997| acc: 0.9157| loss: 0.2402| time: 42.04\n",
      "valid| epoch  6| batch 10000/41997| acc: 0.8981| loss: 0.2882| time: 6.23\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 15000/41997| acc: 0.9220| loss: 0.2204| time: 41.11\n",
      "valid| epoch  6| batch 15000/41997| acc: 0.9054| loss: 0.2671| time: 5.29\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 20000/41997| acc: 0.9157| loss: 0.2322| time: 44.98\n",
      "valid| epoch  6| batch 20000/41997| acc: 0.8979| loss: 0.2831| time: 5.53\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 25000/41997| acc: 0.9248| loss: 0.2141| time: 42.56\n",
      "valid| epoch  6| batch 25000/41997| acc: 0.9048| loss: 0.2658| time: 4.98\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 30000/41997| acc: 0.9132| loss: 0.2330| time: 41.83\n",
      "valid| epoch  6| batch 30000/41997| acc: 0.8935| loss: 0.2865| time: 4.97\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 35000/41997| acc: 0.9134| loss: 0.2363| time: 43.83\n",
      "valid| epoch  6| batch 35000/41997| acc: 0.8952| loss: 0.2909| time: 5.32\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  6| batch 40000/41997| acc: 0.9208| loss: 0.2211| time: 43.69\n",
      "valid| epoch  6| batch 40000/41997| acc: 0.9056| loss: 0.2705| time: 5.24\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 5000/41997| acc: 0.9181| loss: 0.2284| time: 49.70\n",
      "valid| epoch  7| batch 5000/41997| acc: 0.8990| loss: 0.2849| time: 5.39\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 10000/41997| acc: 0.9205| loss: 0.2254| time: 43.23\n",
      "valid| epoch  7| batch 10000/41997| acc: 0.8993| loss: 0.2813| time: 5.05\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 15000/41997| acc: 0.9261| loss: 0.2081| time: 41.67\n",
      "valid| epoch  7| batch 15000/41997| acc: 0.9066| loss: 0.2621| time: 4.95\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 20000/41997| acc: 0.9212| loss: 0.2165| time: 42.55\n",
      "valid| epoch  7| batch 20000/41997| acc: 0.8999| loss: 0.2761| time: 5.17\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 25000/41997| acc: 0.9283| loss: 0.2032| time: 44.81\n",
      "valid| epoch  7| batch 25000/41997| acc: 0.9065| loss: 0.2627| time: 5.07\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 30000/41997| acc: 0.9178| loss: 0.2218| time: 44.27\n",
      "valid| epoch  7| batch 30000/41997| acc: 0.8956| loss: 0.2836| time: 5.21\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 35000/41997| acc: 0.9194| loss: 0.2203| time: 41.85\n",
      "valid| epoch  7| batch 35000/41997| acc: 0.8985| loss: 0.2830| time: 5.24\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  7| batch 40000/41997| acc: 0.9238| loss: 0.2115| time: 40.42\n",
      "valid| epoch  7| batch 40000/41997| acc: 0.9057| loss: 0.2690| time: 5.03\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 5000/41997| acc: 0.9220| loss: 0.2167| time: 46.49\n",
      "valid| epoch  8| batch 5000/41997| acc: 0.9002| loss: 0.2824| time: 5.22\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 10000/41997| acc: 0.9234| loss: 0.2148| time: 40.96\n",
      "valid| epoch  8| batch 10000/41997| acc: 0.8999| loss: 0.2780| time: 6.69\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 15000/41997| acc: 0.9302| loss: 0.1969| time: 40.44\n",
      "valid| epoch  8| batch 15000/41997| acc: 0.9076| loss: 0.2577| time: 5.21\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 20000/41997| acc: 0.9265| loss: 0.2020| time: 42.85\n",
      "valid| epoch  8| batch 20000/41997| acc: 0.9013| loss: 0.2704| time: 5.21\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 25000/41997| acc: 0.9328| loss: 0.1920| time: 40.47\n",
      "valid| epoch  8| batch 25000/41997| acc: 0.9071| loss: 0.2585| time: 5.20\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 30000/41997| acc: 0.9224| loss: 0.2100| time: 43.01\n",
      "valid| epoch  8| batch 30000/41997| acc: 0.8970| loss: 0.2806| time: 5.20\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 35000/41997| acc: 0.9211| loss: 0.2121| time: 39.60\n",
      "valid| epoch  8| batch 35000/41997| acc: 0.8993| loss: 0.2840| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  8| batch 40000/41997| acc: 0.9272| loss: 0.2031| time: 42.44\n",
      "valid| epoch  8| batch 40000/41997| acc: 0.9063| loss: 0.2679| time: 5.12\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 5000/41997| acc: 0.9259| loss: 0.2059| time: 48.50\n",
      "valid| epoch  9| batch 5000/41997| acc: 0.9036| loss: 0.2802| time: 5.27\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 10000/41997| acc: 0.9240| loss: 0.2109| time: 41.76\n",
      "valid| epoch  9| batch 10000/41997| acc: 0.8988| loss: 0.2796| time: 5.63\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 15000/41997| acc: 0.9325| loss: 0.1894| time: 39.90\n",
      "valid| epoch  9| batch 15000/41997| acc: 0.9079| loss: 0.2577| time: 5.04\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 20000/41997| acc: 0.9304| loss: 0.1926| time: 37.85\n",
      "valid| epoch  9| batch 20000/41997| acc: 0.9027| loss: 0.2671| time: 5.17\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 25000/41997| acc: 0.9359| loss: 0.1838| time: 42.04\n",
      "valid| epoch  9| batch 25000/41997| acc: 0.9083| loss: 0.2570| time: 5.06\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 30000/41997| acc: 0.9271| loss: 0.1986| time: 40.80\n",
      "valid| epoch  9| batch 30000/41997| acc: 0.9003| loss: 0.2768| time: 4.98\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 35000/41997| acc: 0.9257| loss: 0.2003| time: 36.79\n",
      "valid| epoch  9| batch 35000/41997| acc: 0.9012| loss: 0.2783| time: 4.96\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  9| batch 40000/41997| acc: 0.9288| loss: 0.1977| time: 40.57\n",
      "valid| epoch  9| batch 40000/41997| acc: 0.9053| loss: 0.2697| time: 4.91\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 5000/41997| acc: 0.9291| loss: 0.1972| time: 40.84\n",
      "valid| epoch 10| batch 5000/41997| acc: 0.9029| loss: 0.2804| time: 6.70\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 10000/41997| acc: 0.9262| loss: 0.2038| time: 40.46\n",
      "valid| epoch 10| batch 10000/41997| acc: 0.9010| loss: 0.2791| time: 4.95\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 15000/41997| acc: 0.9359| loss: 0.1806| time: 38.50\n",
      "valid| epoch 10| batch 15000/41997| acc: 0.9080| loss: 0.2571| time: 5.02\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 20000/41997| acc: 0.9343| loss: 0.1827| time: 43.48\n",
      "valid| epoch 10| batch 20000/41997| acc: 0.9032| loss: 0.2662| time: 5.17\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 25000/41997| acc: 0.9374| loss: 0.1766| time: 40.07\n",
      "valid| epoch 10| batch 25000/41997| acc: 0.9062| loss: 0.2575| time: 5.20\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 30000/41997| acc: 0.9313| loss: 0.1883| time: 43.49\n",
      "valid| epoch 10| batch 30000/41997| acc: 0.9024| loss: 0.2750| time: 5.14\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 35000/41997| acc: 0.9278| loss: 0.1940| time: 38.02\n",
      "valid| epoch 10| batch 35000/41997| acc: 0.9008| loss: 0.2797| time: 5.26\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch 10| batch 40000/41997| acc: 0.9304| loss: 0.1913| time: 44.56\n",
      "valid| epoch 10| batch 40000/41997| acc: 0.9049| loss: 0.2713| time: 5.96\n",
      "-------------------------------------------------------------------------\n",
      "Test Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fashion, y_fashion,\n",
    "                                                    stratify=y_fashion,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"cnn\", cnn_model, num_epochs,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion, log_freq=5000,\n",
    "                    model_fname =\"fashion_cnn\",\n",
    "                    verbose=True, logging=True)\n",
    "\n",
    "# Get test error\n",
    "score = get_test_error(\"cnn\", device, model, X_test, y_test)\n",
    "print(\"Test Accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train| epoch  1| batch 5000/36000| acc: 0.2556| loss: 2.0424| time: 41.71\n",
      "valid| epoch  1| batch 5000/36000| acc: 0.2476| loss: 2.0528| time: 7.87\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 10000/36000| acc: 0.2960| loss: 1.9212| time: 58.80\n",
      "valid| epoch  1| batch 10000/36000| acc: 0.3013| loss: 1.9252| time: 7.62\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 15000/36000| acc: 0.3116| loss: 1.8931| time: 54.62\n",
      "valid| epoch  1| batch 15000/36000| acc: 0.3067| loss: 1.8970| time: 9.58\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 20000/36000| acc: 0.3471| loss: 1.8207| time: 57.78\n",
      "valid| epoch  1| batch 20000/36000| acc: 0.3390| loss: 1.8315| time: 8.21\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 25000/36000| acc: 0.3566| loss: 1.8049| time: 58.79\n",
      "valid| epoch  1| batch 25000/36000| acc: 0.3427| loss: 1.8260| time: 7.10\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 30000/36000| acc: 0.3604| loss: 1.7686| time: 51.31\n",
      "valid| epoch  1| batch 30000/36000| acc: 0.3491| loss: 1.7870| time: 10.66\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  1| batch 35000/36000| acc: 0.3897| loss: 1.7140| time: 49.15\n",
      "valid| epoch  1| batch 35000/36000| acc: 0.3761| loss: 1.7361| time: 9.45\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 5000/36000| acc: 0.3842| loss: 1.7106| time: 56.49\n",
      "valid| epoch  2| batch 5000/36000| acc: 0.3563| loss: 1.7803| time: 7.68\n",
      "-------------------------------------------------------------------------\n",
      "train| epoch  2| batch 10000/36000| acc: 0.3976| loss: 1.6810| time: 56.02\n",
      "valid| epoch  2| batch 10000/36000| acc: 0.3841| loss: 1.6970| time: 7.37\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ch_sizes = [3, 16, 32]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cifar10, y_cifar10,\n",
    "                                                    stratify=y_cifar10,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Instantiate the model with layersizes, Loss fct, optimizer\n",
    "cnn_model = CNN(ch_sizes, k_sizes,\n",
    "                stride, padding, out_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "model = train_model(\"cnn\", cnn_model, num_epochs,\n",
    "                    X_train, y_train, batch_size,\n",
    "                    device, optimizer, criterion, log_freq=5000,\n",
    "                    model_fname =\"cifar10_cnn\",\n",
    "                    verbose=True, logging=True)\n",
    "\n",
    "# Get test error\n",
    "score = get_test_error(\"cnn\", device, model, X_test, y_test)\n",
    "print(\"Test Accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python3 (BioDL)",
   "language": "python",
   "name": "biodl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
